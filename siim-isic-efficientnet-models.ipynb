{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "played-objective",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-26T23:32:13.019461Z",
     "iopub.status.busy": "2021-05-26T23:32:13.018841Z",
     "iopub.status.idle": "2021-05-26T23:32:13.022058Z",
     "shell.execute_reply": "2021-05-26T23:32:13.021420Z",
     "shell.execute_reply.started": "2021-05-26T12:46:27.082744Z"
    },
    "papermill": {
     "duration": 0.049461,
     "end_time": "2021-05-26T23:32:13.022240",
     "exception": false,
     "start_time": "2021-05-26T23:32:12.972779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "if False:\n",
    "    for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "        for filename in filenames:\n",
    "            print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-recipient",
   "metadata": {
    "papermill": {
     "duration": 0.033041,
     "end_time": "2021-05-26T23:32:13.088426",
     "exception": false,
     "start_time": "2021-05-26T23:32:13.055385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2 style=color:Teal align=\"left\"> Table of Contents </h2>\n",
    "\n",
    "#### 1. EfficientNet\n",
    "#### 2. Load Required Libraries\n",
    "#### 3. Configs\n",
    "#### 4. Device\n",
    "#### 5. Paths\n",
    "#### 6. Augmentation\n",
    "#### 7. Get dataset\n",
    "#### 8. EDA\n",
    "#### 9. Monitor model performance\n",
    "#### 10. Build model\n",
    "#### 11. kFold\n",
    "#### 12. Evaluate on test\n",
    "#### 13. Submit predictions\n",
    "#### References\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-health",
   "metadata": {
    "papermill": {
     "duration": 0.033,
     "end_time": "2021-05-26T23:32:13.155252",
     "exception": false,
     "start_time": "2021-05-26T23:32:13.122252",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 1. EfficientNet </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-direction",
   "metadata": {
    "papermill": {
     "duration": 0.037312,
     "end_time": "2021-05-26T23:32:13.226199",
     "exception": false,
     "start_time": "2021-05-26T23:32:13.188887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div align=\"left\">\n",
    "<font size=\"4\"> Model Size vs. ImageNet Accuracy.  </font>  \n",
    "</div> \n",
    "\n",
    "EfficientNets significantly outperform other Convoluational Neural Networks [Tan, M. and Le, Q.V.. 2019]. \n",
    "\n",
    "<img align=\"left\" src=\"https://raw.githubusercontent.com/kabartay/kaggle-siim-isic-melanoma-classification/master/materials/flops.jpg\" data-canonical-src=\"https://raw.githubusercontent.com/kabartay/kaggle-siim-isic-melanoma-classification/master/materials/flops.jpg\" width=\"650\" height=\"650\" />  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "desperate-falls",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T23:32:13.311938Z",
     "iopub.status.busy": "2021-05-26T23:32:13.311179Z",
     "iopub.status.idle": "2021-05-26T23:32:21.799463Z",
     "shell.execute_reply": "2021-05-26T23:32:21.798912Z",
     "shell.execute_reply.started": "2021-05-26T12:46:27.089186Z"
    },
    "papermill": {
     "duration": 8.534288,
     "end_time": "2021-05-26T23:32:21.799625",
     "exception": false,
     "start_time": "2021-05-26T23:32:13.265337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EfficientNet\n",
    "!pip install -q efficientnet >> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-stupid",
   "metadata": {
    "papermill": {
     "duration": 0.03382,
     "end_time": "2021-05-26T23:32:21.866809",
     "exception": false,
     "start_time": "2021-05-26T23:32:21.832989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div align=\"center\">\n",
    "<font size=\"4\"> EfficientNetB0  </font>  \n",
    "</div>\n",
    "\n",
    "<img align=\"center\" src=\"https://raw.githubusercontent.com/kabartay/kaggle-siim-isic-melanoma-classification/master/materials/efficientnetb0_.png\" data-canonical-src=\"https://raw.githubusercontent.com/kabartay/kaggle-siim-isic-melanoma-classification/master/materials/efficientnetb0_.png\" width=\"1550\" height=\"1550\" />\n",
    "\n",
    "Image: [T. A. Putra et al 2020]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "theoretical-colors",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T23:32:21.938968Z",
     "iopub.status.busy": "2021-05-26T23:32:21.938247Z",
     "iopub.status.idle": "2021-05-26T23:32:21.941363Z",
     "shell.execute_reply": "2021-05-26T23:32:21.940890Z",
     "shell.execute_reply.started": "2021-05-26T12:46:33.599059Z"
    },
    "papermill": {
     "duration": 0.041049,
     "end_time": "2021-05-26T23:32:21.941529",
     "exception": false,
     "start_time": "2021-05-26T23:32:21.900480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select EfficientNetBx to use\n",
    "# EfficientNetB0\n",
    "# EfficientNetB1\n",
    "# EfficientNetB2\n",
    "# EfficientNetB3\n",
    "# EfficientNetB4\n",
    "# EfficientNetB5\n",
    "# EfficientNetB6\n",
    "# EfficientNetB7\n",
    "\n",
    "MODEL = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-finding",
   "metadata": {
    "papermill": {
     "duration": 0.032337,
     "end_time": "2021-05-26T23:32:22.006633",
     "exception": false,
     "start_time": "2021-05-26T23:32:21.974296",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 2. Load Required Libraries </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "identical-balloon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T23:32:22.076481Z",
     "iopub.status.busy": "2021-05-26T23:32:22.075835Z",
     "iopub.status.idle": "2021-05-26T23:32:28.611842Z",
     "shell.execute_reply": "2021-05-26T23:32:28.611243Z",
     "shell.execute_reply.started": "2021-05-26T12:46:33.606533Z"
    },
    "papermill": {
     "duration": 6.571827,
     "end_time": "2021-05-26T23:32:28.612006",
     "exception": false,
     "start_time": "2021-05-26T23:32:22.040179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import math\n",
    "\n",
    "import random\n",
    "random.seed(a=42)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import PIL\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import efficientnet.tfkeras as efn\n",
    "\n",
    "from kaggle_datasets import KaggleDatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-brunswick",
   "metadata": {
    "papermill": {
     "duration": 0.032727,
     "end_time": "2021-05-26T23:32:28.678036",
     "exception": false,
     "start_time": "2021-05-26T23:32:28.645309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 3. Configs </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "indie-stocks",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T23:32:28.747269Z",
     "iopub.status.busy": "2021-05-26T23:32:28.746656Z",
     "iopub.status.idle": "2021-05-26T23:32:28.752953Z",
     "shell.execute_reply": "2021-05-26T23:32:28.753465Z",
     "shell.execute_reply.started": "2021-05-26T12:46:33.621303Z"
    },
    "papermill": {
     "duration": 0.04248,
     "end_time": "2021-05-26T23:32:28.753651",
     "exception": false,
     "start_time": "2021-05-26T23:32:28.711171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFG = dict(\n",
    "    net_count         =   7, \n",
    "    batch_size        =   8,  # 8; 16; 32; 64; bigger batch size => moemry allocation issue\n",
    "    epochs            =   20, # 5; 10; 20;\n",
    "    verbose           =   1,  # 0; 1\n",
    "    \n",
    "    optimizer         = 'adam',\n",
    "    \n",
    "    # kFold\n",
    "    NSPLITS           = 5,  \n",
    "    RANDOM_STATE      = 42,   \n",
    "    \n",
    "    # LR\n",
    "    LR_START          =   0.000005, # 5e-6\n",
    "    LR_MAX            =   0.000010, # 1e-5; 2e-5; 3e-5\n",
    "    LR_MIN            =   0.000001, # 1e-6\n",
    "    LR_RAMPUP_EPOCHS  =   5,\n",
    "    LR_SUSTAIN_EPOCHS =   0,\n",
    "    LR_EXP_DECAY      =   0.8,\n",
    "    \n",
    "    # Images sizes\n",
    "    read_size         = 256, # 256 (a); 384 (b); 512 (c); 768 (d);\n",
    "    crop_size         = 250, # 250 (a); 370 (b); 500 (c); 750 (d);\n",
    "    net_size          = 240, # 240 (a); 352 (b); 480 (c); 730 (d);\n",
    "    \n",
    "    # Images augs\n",
    "    ROTATION          = 180.0,\n",
    "    SHEAR             =   2.0,\n",
    "    HZOOM             =   8.0,\n",
    "    WZOOM             =   8.0,\n",
    "    HSHIFT            =   8.0,\n",
    "    WSHIFT            =   8.0,\n",
    "\n",
    "    # Postprocessing\n",
    "    label_smooth_fac  =   0, # 0.01; 0.05; 0.1; 0.2;\n",
    "    tta_steps         =   10  # 5; 10; 15; 25; 30;\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-reaction",
   "metadata": {
    "papermill": {
     "duration": 0.033033,
     "end_time": "2021-05-26T23:32:28.819442",
     "exception": false,
     "start_time": "2021-05-26T23:32:28.786409",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 4. Device </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "entitled-discharge",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T23:32:28.888835Z",
     "iopub.status.busy": "2021-05-26T23:32:28.888141Z",
     "iopub.status.idle": "2021-05-26T23:32:28.891281Z",
     "shell.execute_reply": "2021-05-26T23:32:28.891905Z",
     "shell.execute_reply.started": "2021-05-26T12:46:33.632979Z"
    },
    "papermill": {
     "duration": 0.039827,
     "end_time": "2021-05-26T23:32:28.892068",
     "exception": false,
     "start_time": "2021-05-26T23:32:28.852241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = \"TPU\"\n",
    "#DEVICE = \"GPU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "scientific-adelaide",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T23:32:28.961123Z",
     "iopub.status.busy": "2021-05-26T23:32:28.960473Z",
     "iopub.status.idle": "2021-05-26T23:32:34.727052Z",
     "shell.execute_reply": "2021-05-26T23:32:34.726196Z",
     "shell.execute_reply.started": "2021-05-26T12:46:33.648475Z"
    },
    "papermill": {
     "duration": 5.802248,
     "end_time": "2021-05-26T23:32:34.727240",
     "exception": false,
     "start_time": "2021-05-26T23:32:28.924992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting to TPU...\n",
      "Running on TPU  grpc://10.0.0.2:8470\n",
      "initializing  TPU ...\n",
      "TPU initialized\n",
      "REPLICAS: 8\n"
     ]
    }
   ],
   "source": [
    "if DEVICE == \"TPU\":\n",
    "    print(\"connecting to TPU...\")\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        print('Running on TPU ', tpu.master())\n",
    "    except ValueError:\n",
    "        print(\"Could not connect to TPU\")\n",
    "        tpu = None\n",
    "\n",
    "    if tpu:\n",
    "        try:\n",
    "            print(\"initializing  TPU ...\")\n",
    "            tf.config.experimental_connect_to_cluster(tpu)\n",
    "            tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "            print(\"TPU initialized\")\n",
    "        except _:\n",
    "            print(\"failed to initialize TPU\")\n",
    "    else:\n",
    "        DEVICE = \"GPU\"\n",
    "\n",
    "if DEVICE != \"TPU\":\n",
    "    print(\"Using default strategy for CPU and single GPU\")\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "if DEVICE == \"GPU\":\n",
    "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "    \n",
    "\n",
    "AUTO     = tf.data.experimental.AUTOTUNE\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "print(f'REPLICAS: {REPLICAS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "plain-teaching",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T23:32:34.800626Z",
     "iopub.status.busy": "2021-05-26T23:32:34.799970Z",
     "iopub.status.idle": "2021-05-26T23:32:35.536679Z",
     "shell.execute_reply": "2021-05-26T23:32:35.536146Z",
     "shell.execute_reply.started": "2021-05-26T12:46:39.836173Z"
    },
    "papermill": {
     "duration": 0.774765,
     "end_time": "2021-05-26T23:32:35.536831",
     "exception": false,
     "start_time": "2021-05-26T23:32:34.762066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: nvidia-smi: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-stage",
   "metadata": {
    "papermill": {
     "duration": 0.033523,
     "end_time": "2021-05-26T23:32:35.604335",
     "exception": false,
     "start_time": "2021-05-26T23:32:35.570812",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 5. Paths </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "greenhouse-despite",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T23:32:35.679014Z",
     "iopub.status.busy": "2021-05-26T23:32:35.678388Z",
     "iopub.status.idle": "2021-05-26T23:32:35.826950Z",
     "shell.execute_reply": "2021-05-26T23:32:35.826386Z",
     "shell.execute_reply.started": "2021-05-26T12:46:40.602641Z"
    },
    "papermill": {
     "duration": 0.188341,
     "end_time": "2021-05-26T23:32:35.827099",
     "exception": false,
     "start_time": "2021-05-26T23:32:35.638758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASEPATH = \"../input/siim-isic-melanoma-classification\"\n",
    "df_train = pd.read_csv(os.path.join(BASEPATH, 'train.csv'))\n",
    "df_test  = pd.read_csv(os.path.join(BASEPATH, 'test.csv'))\n",
    "df_sub   = pd.read_csv(os.path.join(BASEPATH, 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-richardson",
   "metadata": {
    "papermill": {
     "duration": 0.03505,
     "end_time": "2021-05-26T23:32:35.896087",
     "exception": false,
     "start_time": "2021-05-26T23:32:35.861037",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We have images in TFRecords of different sizes:\n",
    "- 256x256\n",
    "- 384x384\n",
    "- 512x512\n",
    "- 768x768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "apparent-moderator",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T23:32:35.974811Z",
     "iopub.status.busy": "2021-05-26T23:32:35.968168Z",
     "iopub.status.idle": "2021-05-26T23:32:36.730220Z",
     "shell.execute_reply": "2021-05-26T23:32:36.730718Z",
     "shell.execute_reply.started": "2021-05-26T12:46:40.699968Z"
    },
    "papermill": {
     "duration": 0.800902,
     "end_time": "2021-05-26T23:32:36.730901",
     "exception": false,
     "start_time": "2021-05-26T23:32:35.929999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/melanoma-256x256:\r\n",
      "test00-687.tfrec  test08-687.tfrec  train.csv\t\ttrain07-2174.tfrec\r\n",
      "test01-687.tfrec  test09-687.tfrec  train00-2182.tfrec\ttrain08-2177.tfrec\r\n",
      "test02-687.tfrec  test10-687.tfrec  train01-2185.tfrec\ttrain09-2178.tfrec\r\n",
      "test03-687.tfrec  test11-687.tfrec  train02-2193.tfrec\ttrain10-2174.tfrec\r\n",
      "test04-687.tfrec  test12-687.tfrec  train03-2182.tfrec\ttrain11-2176.tfrec\r\n",
      "test05-687.tfrec  test13-687.tfrec  train04-2167.tfrec\ttrain12-2198.tfrec\r\n",
      "test06-687.tfrec  test14-687.tfrec  train05-2171.tfrec\ttrain13-2186.tfrec\r\n",
      "test07-687.tfrec  test15-677.tfrec  train06-2175.tfrec\ttrain14-2174.tfrec\r\n",
      "\r\n",
      "../input/melanoma-384x384:\r\n",
      "test00-687.tfrec  test08-687.tfrec  train.csv\t\ttrain07-2174.tfrec\r\n",
      "test01-687.tfrec  test09-687.tfrec  train00-2182.tfrec\ttrain08-2177.tfrec\r\n",
      "test02-687.tfrec  test10-687.tfrec  train01-2185.tfrec\ttrain09-2178.tfrec\r\n",
      "test03-687.tfrec  test11-687.tfrec  train02-2193.tfrec\ttrain10-2174.tfrec\r\n",
      "test04-687.tfrec  test12-687.tfrec  train03-2182.tfrec\ttrain11-2176.tfrec\r\n",
      "test05-687.tfrec  test13-687.tfrec  train04-2167.tfrec\ttrain12-2198.tfrec\r\n",
      "test06-687.tfrec  test14-687.tfrec  train05-2171.tfrec\ttrain13-2186.tfrec\r\n",
      "test07-687.tfrec  test15-677.tfrec  train06-2175.tfrec\ttrain14-2174.tfrec\r\n",
      "\r\n",
      "../input/melanoma-512x512:\r\n",
      "test00-687.tfrec  test08-687.tfrec  train.csv\t\ttrain07-2174.tfrec\r\n",
      "test01-687.tfrec  test09-687.tfrec  train00-2182.tfrec\ttrain08-2177.tfrec\r\n",
      "test02-687.tfrec  test10-687.tfrec  train01-2185.tfrec\ttrain09-2178.tfrec\r\n",
      "test03-687.tfrec  test11-687.tfrec  train02-2193.tfrec\ttrain10-2174.tfrec\r\n",
      "test04-687.tfrec  test12-687.tfrec  train03-2182.tfrec\ttrain11-2176.tfrec\r\n",
      "test05-687.tfrec  test13-687.tfrec  train04-2167.tfrec\ttrain12-2198.tfrec\r\n",
      "test06-687.tfrec  test14-687.tfrec  train05-2171.tfrec\ttrain13-2186.tfrec\r\n",
      "test07-687.tfrec  test15-677.tfrec  train06-2175.tfrec\ttrain14-2174.tfrec\r\n",
      "\r\n",
      "../input/melanoma-768x768:\r\n",
      "test00-687.tfrec  test08-687.tfrec  train.csv\t\ttrain07-2174.tfrec\r\n",
      "test01-687.tfrec  test09-687.tfrec  train00-2182.tfrec\ttrain08-2177.tfrec\r\n",
      "test02-687.tfrec  test10-687.tfrec  train01-2185.tfrec\ttrain09-2178.tfrec\r\n",
      "test03-687.tfrec  test11-687.tfrec  train02-2193.tfrec\ttrain10-2174.tfrec\r\n",
      "test04-687.tfrec  test12-687.tfrec  train03-2182.tfrec\ttrain11-2176.tfrec\r\n",
      "test05-687.tfrec  test13-687.tfrec  train04-2167.tfrec\ttrain12-2198.tfrec\r\n",
      "test06-687.tfrec  test14-687.tfrec  train05-2171.tfrec\ttrain13-2186.tfrec\r\n",
      "test07-687.tfrec  test15-677.tfrec  train06-2175.tfrec\ttrain14-2174.tfrec\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../input/melanoma*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hydraulic-probe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T23:32:36.805555Z",
     "iopub.status.busy": "2021-05-26T23:32:36.804622Z",
     "iopub.status.idle": "2021-05-26T23:32:36.807585Z",
     "shell.execute_reply": "2021-05-26T23:32:36.807031Z",
     "shell.execute_reply.started": "2021-05-26T12:46:41.459446Z"
    },
    "papermill": {
     "duration": 0.042369,
     "end_time": "2021-05-26T23:32:36.807719",
     "exception": false,
     "start_time": "2021-05-26T23:32:36.765350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select image size of ionterest\n",
    "SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "synthetic-security",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T23:32:36.891235Z",
     "iopub.status.busy": "2021-05-26T23:32:36.890552Z",
     "iopub.status.idle": "2021-05-26T23:32:37.436887Z",
     "shell.execute_reply": "2021-05-26T23:32:37.437365Z",
     "shell.execute_reply.started": "2021-05-26T12:46:41.465231Z"
    },
    "papermill": {
     "duration": 0.59539,
     "end_time": "2021-05-26T23:32:37.437576",
     "exception": false,
     "start_time": "2021-05-26T23:32:36.842186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "GCS_PATH    = KaggleDatasets().get_gcs_path('melanoma-%ix%i' % (SIZE,SIZE))\n",
    "#GCS_PATH    = KaggleDatasets().get_gcs_path('melanoma-256x256')\n",
    "#GCS_PATH    = KaggleDatasets().get_gcs_path('melanoma-384x384')\n",
    "#GCS_PATH    = KaggleDatasets().get_gcs_path('melanoma-512x512')\n",
    "#GCS_PATH    = KaggleDatasets().get_gcs_path('melanoma-768x768')\n",
    "files_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH + '/train*.tfrec')))\n",
    "files_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH + '/test*.tfrec')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "assisted-fence",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T23:32:37.509594Z",
     "iopub.status.busy": "2021-05-26T23:32:37.508956Z",
     "iopub.status.idle": "2021-05-26T23:32:37.548764Z",
     "shell.execute_reply": "2021-05-26T23:32:37.549260Z",
     "shell.execute_reply.started": "2021-05-26T12:46:41.931527Z"
    },
    "papermill": {
     "duration": 0.077316,
     "end_time": "2021-05-26T23:32:37.549437",
     "exception": false,
     "start_time": "2021-05-26T23:32:37.472121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33126 32542 584\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train),len(df_train[df_train.target==0]),len(df_train[df_train.target==1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-titanium",
   "metadata": {
    "papermill": {
     "duration": 0.034392,
     "end_time": "2021-05-26T23:32:37.618299",
     "exception": false,
     "start_time": "2021-05-26T23:32:37.583907",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 6. Augmentation </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "norwegian-disclosure",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T23:32:37.708707Z",
     "iopub.status.busy": "2021-05-26T23:32:37.707875Z",
     "iopub.status.idle": "2021-05-26T23:32:37.710265Z",
     "shell.execute_reply": "2021-05-26T23:32:37.710775Z",
     "shell.execute_reply.started": "2021-05-26T12:46:41.947475Z"
    },
    "papermill": {
     "duration": 0.057384,
     "end_time": "2021-05-26T23:32:37.710952",
     "exception": false,
     "start_time": "2021-05-26T23:32:37.653568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# by Chris Deotte\n",
    "\n",
    "def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n",
    "    # returns 3x3 transformmatrix which transforms indicies\n",
    "        \n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    shear    = math.pi * shear    / 180.\n",
    "\n",
    "    def get_3x3_mat(lst):\n",
    "        return tf.reshape(tf.concat([lst],axis=0), [3,3])\n",
    "    \n",
    "    \n",
    "    # ROTATION MATRIX\n",
    "    c1   = tf.math.cos(rotation)\n",
    "    s1   = tf.math.sin(rotation)\n",
    "    one  = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    \n",
    "    rotation_matrix = get_3x3_mat([c1,   s1,   zero, \n",
    "                                   -s1,  c1,   zero, \n",
    "                                   zero, zero, one])    \n",
    "    # SHEAR MATRIX\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)\n",
    "    shear_matrix = get_3x3_mat([one,  s2,   zero, \n",
    "                                zero, c2,   zero, \n",
    "                                zero, zero, one])   \n",
    "    \n",
    "    # ZOOM MATRIX\n",
    "    zoom_matrix = get_3x3_mat([one/height_zoom, zero,           zero, \n",
    "                               zero,            one/width_zoom, zero, \n",
    "                               zero,            zero,           one])    \n",
    "    # SHIFT MATRIX\n",
    "    shift_matrix = get_3x3_mat([one,  zero, height_shift, \n",
    "                                zero, one,  width_shift, \n",
    "                                zero, zero, one])\n",
    "    \n",
    "    return K.dot(K.dot(rotation_matrix, shear_matrix), \n",
    "                 K.dot(zoom_matrix,     shift_matrix))\n",
    "\n",
    "\n",
    "def transform(image, cfg):    \n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated, sheared, zoomed, and shifted\n",
    "    DIM = cfg[\"read_size\"]\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    rot = cfg['ROTATION'] * tf.random.normal([1], dtype='float32')\n",
    "    shr = cfg['SHEAR'] * tf.random.normal([1], dtype='float32') \n",
    "    h_zoom = 1.0 + tf.random.normal([1], dtype='float32') / cfg['HZOOM']\n",
    "    w_zoom = 1.0 + tf.random.normal([1], dtype='float32') / cfg['WZOOM']\n",
    "    h_shift = cfg['HSHIFT'] * tf.random.normal([1], dtype='float32') \n",
    "    w_shift = cfg['WSHIFT'] * tf.random.normal([1], dtype='float32') \n",
    "\n",
    "    # GET TRANSFORMATION MATRIX\n",
    "    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x   = tf.repeat(tf.range(DIM//2, -DIM//2,-1), DIM)\n",
    "    y   = tf.tile(tf.range(-DIM//2, DIM//2), [DIM])\n",
    "    z   = tf.ones([DIM*DIM], dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(m, tf.cast(idx, dtype='float32'))\n",
    "    idx2 = K.cast(idx2, dtype='int32')\n",
    "    idx2 = K.clip(idx2, -DIM//2+XDIM+1, DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES           \n",
    "    idx3 = tf.stack([DIM//2-idx2[0,], DIM//2-1+idx2[1,]])\n",
    "    d    = tf.gather_nd(image, tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d,[DIM, DIM,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "disciplinary-african",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T23:32:37.784359Z",
     "iopub.status.busy": "2021-05-26T23:32:37.783379Z",
     "iopub.status.idle": "2021-05-26T23:32:37.993725Z",
     "shell.execute_reply": "2021-05-26T23:32:37.994237Z",
     "shell.execute_reply.started": "2021-05-26T12:46:41.973328Z"
    },
    "papermill": {
     "duration": 0.248641,
     "end_time": "2021-05-26T23:32:37.994415",
     "exception": false,
     "start_time": "2021-05-26T23:32:37.745774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_labeled_tfrecord(example):\n",
    "    tfrec_format = {\n",
    "        'image'                        : tf.io.FixedLenFeature([], tf.string),\n",
    "        'image_name'                   : tf.io.FixedLenFeature([], tf.string),\n",
    "        'patient_id'                   : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'sex'                          : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'age_approx'                   : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'anatom_site_general_challenge': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'diagnosis'                    : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'target'                       : tf.io.FixedLenFeature([], tf.int64)\n",
    "    }           \n",
    "    example = tf.io.parse_single_example(example, tfrec_format)\n",
    "    return example['image'], example['target']\n",
    "\n",
    "\n",
    "def read_unlabeled_tfrecord(example, return_image_name):\n",
    "    tfrec_format = {\n",
    "        'image'                        : tf.io.FixedLenFeature([], tf.string),\n",
    "        'image_name'                   : tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrec_format)\n",
    "    return example['image'], example['image_name'] if return_image_name else 0\n",
    "\n",
    " \n",
    "def prepare_image(img, cfg=None, augment=True):    \n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [cfg['read_size'], cfg['read_size']])\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    \n",
    "    if augment:\n",
    "        img = transform(img, cfg)\n",
    "        img = tf.image.random_crop(img, [cfg['crop_size'], cfg['crop_size'], 3])\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_hue(img, 0.01)                # 0.01; 0.015; 0.02\n",
    "        img = tf.image.random_saturation(img, 0.75, 1.25)   # 0.5,1.5; 0.7,1.3; 0.8, 1.2; 0.9,1.1;\n",
    "        img = tf.image.random_contrast(img, 0.8, 1.2)       # 0.9,1.1; 0.8,1.2;\n",
    "        img = tf.image.random_brightness(img, 0.1)          # 0.10; 0.15; 0.20;\n",
    "\n",
    "    else:\n",
    "        img = tf.image.central_crop(img, cfg['crop_size'] / cfg['read_size'])\n",
    "                                   \n",
    "    img = tf.image.resize(img, [cfg['net_size'], cfg['net_size']])\n",
    "    img = tf.reshape(img, [cfg['net_size'], cfg['net_size'], 3])\n",
    "    return img\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) \n",
    "         for filename in filenames]\n",
    "    return np.sum(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-honduras",
   "metadata": {
    "papermill": {
     "duration": 0.034468,
     "end_time": "2021-05-26T23:32:38.063894",
     "exception": false,
     "start_time": "2021-05-26T23:32:38.029426",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 7. Get dataset </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "placed-order",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T23:32:38.136137Z",
     "iopub.status.busy": "2021-05-26T23:32:38.135438Z",
     "iopub.status.idle": "2021-05-26T23:32:38.143730Z",
     "shell.execute_reply": "2021-05-26T23:32:38.144226Z",
     "shell.execute_reply.started": "2021-05-26T12:46:41.991902Z"
    },
    "papermill": {
     "duration": 0.046064,
     "end_time": "2021-05-26T23:32:38.144404",
     "exception": false,
     "start_time": "2021-05-26T23:32:38.098340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataset(files, cfg, \n",
    "                augment = False, \n",
    "                shuffle = False, \n",
    "                repeat = False, \n",
    "                labeled=True, \n",
    "                return_image_names=True\n",
    "               ):\n",
    "    \n",
    "    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n",
    "    ds = ds.cache()\n",
    "    \n",
    "    if repeat:\n",
    "        ds = ds.repeat()\n",
    "    \n",
    "    if shuffle: \n",
    "        ds = ds.shuffle(1024*8)\n",
    "        opt = tf.data.Options()\n",
    "        opt.experimental_deterministic = False\n",
    "        ds = ds.with_options(opt)\n",
    "        \n",
    "    if labeled: \n",
    "        ds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n",
    "    else:\n",
    "        ds = ds.map(lambda example: read_unlabeled_tfrecord(example, return_image_names), num_parallel_calls=AUTO)      \n",
    "    \n",
    "    ds = ds.map(lambda img, imgname_or_label: (prepare_image(img, augment=augment, cfg=cfg), imgname_or_label), num_parallel_calls=AUTO)\n",
    "    \n",
    "    ds = ds.batch(cfg['batch_size'] * REPLICAS)\n",
    "    ds = ds.prefetch(AUTO)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-royal",
   "metadata": {
    "papermill": {
     "duration": 0.034763,
     "end_time": "2021-05-26T23:32:38.214245",
     "exception": false,
     "start_time": "2021-05-26T23:32:38.179482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 8. EDA </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "valued-virginia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T23:32:38.288002Z",
     "iopub.status.busy": "2021-05-26T23:32:38.287308Z",
     "iopub.status.idle": "2021-05-26T23:32:38.294410Z",
     "shell.execute_reply": "2021-05-26T23:32:38.294882Z",
     "shell.execute_reply.started": "2021-05-26T12:46:42.011522Z"
    },
    "papermill": {
     "duration": 0.045166,
     "end_time": "2021-05-26T23:32:38.295078",
     "exception": false,
     "start_time": "2021-05-26T23:32:38.249912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_dataset(thumb_size, cols, rows, ds):\n",
    "    mosaic = PIL.Image.new(mode='RGB', size=(thumb_size*cols + (cols-1), thumb_size*rows + (rows-1)))\n",
    "   \n",
    "    for idx, data in enumerate(iter(ds)):\n",
    "        img, target_or_imgid = data\n",
    "        ix  = idx % cols\n",
    "        iy  = idx // cols\n",
    "        img = np.clip(img.numpy() * 255, 0, 255).astype(np.uint8)\n",
    "        img = PIL.Image.fromarray(img)\n",
    "        img = img.resize((thumb_size, thumb_size), resample=PIL.Image.BILINEAR)\n",
    "        mosaic.paste(img, (ix*thumb_size + ix, iy*thumb_size + iy))\n",
    "\n",
    "    display(mosaic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "quality-holmes",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T23:32:38.367563Z",
     "iopub.status.busy": "2021-05-26T23:32:38.366929Z",
     "iopub.status.idle": "2021-05-26T23:32:38.726898Z",
     "shell.execute_reply": "2021-05-26T23:32:38.726322Z",
     "shell.execute_reply.started": "2021-05-26T12:46:42.030821Z"
    },
    "papermill": {
     "duration": 0.397123,
     "end_time": "2021-05-26T23:32:38.727048",
     "exception": false,
     "start_time": "2021-05-26T23:32:38.329925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nrows = 6\n",
    "ncols = 12\n",
    "ds = get_dataset(files_train, CFG).unbatch().take(nrows*ncols)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "written-nudist",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T23:32:38.804372Z",
     "iopub.status.busy": "2021-05-26T23:32:38.803735Z",
     "iopub.status.idle": "2021-05-26T23:32:39.506900Z",
     "shell.execute_reply": "2021-05-26T23:32:39.506053Z",
     "shell.execute_reply.started": "2021-05-26T12:46:42.284564Z"
    },
    "papermill": {
     "duration": 0.745144,
     "end_time": "2021-05-26T23:32:39.507118",
     "exception": false,
     "start_time": "2021-05-26T23:32:38.761974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = tf.data.TFRecordDataset(files_train, num_parallel_reads=AUTO)\n",
    "ds = ds.take(1).cache().repeat()\n",
    "ds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n",
    "ds = ds.map(lambda img, target: (prepare_image(img, cfg=CFG, augment=True), target), num_parallel_calls=AUTO)\n",
    "ds = ds.take(12*6)\n",
    "ds = ds.prefetch(AUTO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-lobby",
   "metadata": {
    "papermill": {
     "duration": 0.034534,
     "end_time": "2021-05-26T23:32:39.583963",
     "exception": false,
     "start_time": "2021-05-26T23:32:39.549429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 9. Monitor model performance </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "italic-strap",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T23:32:39.662122Z",
     "iopub.status.busy": "2021-05-26T23:32:39.661276Z",
     "iopub.status.idle": "2021-05-26T23:32:39.664570Z",
     "shell.execute_reply": "2021-05-26T23:32:39.665038Z",
     "shell.execute_reply.started": "2021-05-26T12:46:45.07075Z"
    },
    "papermill": {
     "duration": 0.046522,
     "end_time": "2021-05-26T23:32:39.665199",
     "exception": false,
     "start_time": "2021-05-26T23:32:39.618677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lr_callback(cfg):\n",
    "    lr_start   = cfg['LR_START']\n",
    "    lr_max     = cfg['LR_MAX'] * strategy.num_replicas_in_sync # can be set dynamic cfg['LR_MAX']*cfg['batch_size'] * replicas\n",
    "    lr_min     = cfg['LR_MIN']\n",
    "    lr_ramp_ep = cfg['LR_RAMPUP_EPOCHS']\n",
    "    lr_sus_ep  = cfg['LR_SUSTAIN_EPOCHS']\n",
    "    lr_decay   = cfg['LR_EXP_DECAY']\n",
    "   \n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep:\n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "            \n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "            lr = lr_max\n",
    "            \n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "            \n",
    "        return lr\n",
    "\n",
    "    #lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n",
    "    lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                                       factor=0.25, \n",
    "                                                       patience=2, \n",
    "                                                       verbose=0, \n",
    "                                                       mode='auto'\n",
    "                                                      )\n",
    "    return lr_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-saskatchewan",
   "metadata": {
    "papermill": {
     "duration": 0.034817,
     "end_time": "2021-05-26T23:32:39.734781",
     "exception": false,
     "start_time": "2021-05-26T23:32:39.699964",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 10. Build model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "turkish-diagram",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T23:32:39.811275Z",
     "iopub.status.busy": "2021-05-26T23:32:39.810284Z",
     "iopub.status.idle": "2021-05-26T23:32:39.820011Z",
     "shell.execute_reply": "2021-05-26T23:32:39.820578Z",
     "shell.execute_reply.started": "2021-05-26T12:46:45.081522Z"
    },
    "papermill": {
     "duration": 0.050229,
     "end_time": "2021-05-26T23:32:39.820749",
     "exception": false,
     "start_time": "2021-05-26T23:32:39.770520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model(cfg):\n",
    "    model_input = tf.keras.Input(shape=(cfg['net_size'], cfg['net_size'], 3), name='imgIn')\n",
    "\n",
    "    dummy = tf.keras.layers.Lambda(lambda x:x)(model_input)\n",
    "\n",
    "    #constructor = getattr(efn, f'EfficientNetB1')\n",
    "    constructor = getattr(efn, 'EfficientNetB{}'.format(MODEL)) # 1,3,5,6,7\n",
    "    x = constructor(include_top=False, weights='imagenet', \n",
    "                    input_shape=(cfg['net_size'], cfg['net_size'], 3), \n",
    "                    pooling='avg')(dummy)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    outputs = [x]\n",
    "        \n",
    "    model = tf.keras.Model(model_input, outputs, name='aNetwork')\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def compile_new_model(cfg):    \n",
    "    with strategy.scope():\n",
    "        model = get_model(cfg)\n",
    "        \n",
    "        #losses = tf.keras.losses.BinaryCrossentropy() # default from_logits=False\n",
    "        #losses = [tf.keras.losses.BinaryCrossentropy(label_smoothing = cfg['label_smooth_fac'])]\n",
    "        #losses = [tf.keras.losses.BinaryCrossentropy(label_smoothing = cfg['label_smooth_fac']) for i in range(cfg['net_count'])]\n",
    "        losses = [tf.keras.losses.BinaryCrossentropy(label_smoothing = cfg['label_smooth_fac']) if cfg['label_smooth_fac'] > 0 else  tf.keras.losses.BinaryCrossentropy()]\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer = cfg['optimizer'],\n",
    "            loss      = losses,\n",
    "            metrics   = [tf.keras.metrics.AUC(name='auc')])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-aquatic",
   "metadata": {
    "papermill": {
     "duration": 0.035147,
     "end_time": "2021-05-26T23:32:39.890802",
     "exception": false,
     "start_time": "2021-05-26T23:32:39.855655",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`label_smoothing`\n",
    "- Float in [0, 1]. \n",
    "    - When 0, no smoothing occurs. \n",
    "    - When > 0, we compute the loss between the predicted labels and a smoothed version of the true labels, where the smoothing squeezes the labels towards 0.5. Larger values of `label_smoothing` correspond to heavier smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-celebrity",
   "metadata": {
    "papermill": {
     "duration": 0.034765,
     "end_time": "2021-05-26T23:32:39.961047",
     "exception": false,
     "start_time": "2021-05-26T23:32:39.926282",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 11. kFold </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "uniform-battery",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T23:32:40.034264Z",
     "iopub.status.busy": "2021-05-26T23:32:40.033316Z",
     "iopub.status.idle": "2021-05-26T23:32:40.037598Z",
     "shell.execute_reply": "2021-05-26T23:32:40.038160Z",
     "shell.execute_reply.started": "2021-05-26T12:46:45.106193Z"
    },
    "papermill": {
     "duration": 0.042499,
     "end_time": "2021-05-26T23:32:40.038319",
     "exception": false,
     "start_time": "2021-05-26T23:32:39.995820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=CFG['NSPLITS'], \n",
    "              shuffle = True, \n",
    "              random_state = CFG['RANDOM_STATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "governmental-slovenia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T23:32:40.111426Z",
     "iopub.status.busy": "2021-05-26T23:32:40.110526Z",
     "iopub.status.idle": "2021-05-26T23:32:40.116564Z",
     "shell.execute_reply": "2021-05-26T23:32:40.117142Z",
     "shell.execute_reply.started": "2021-05-26T12:46:45.121457Z"
    },
    "papermill": {
     "duration": 0.044382,
     "end_time": "2021-05-26T23:32:40.117303",
     "exception": false,
     "start_time": "2021-05-26T23:32:40.072921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OPTIONS\n",
    "\n",
    "# TRAIN\n",
    "optAug_tr                = True\n",
    "optShuffle_tr            = True \n",
    "optRepeat_tr             = True\n",
    "\n",
    "# TRAIN AUG\n",
    "optAug_trAug             = True\n",
    "optRepeat_trAug          = True\n",
    "optLabeled_trAug         = False\n",
    "optReturnImgNames_trAug  = False\n",
    "\n",
    "\n",
    "# VALIDATION\n",
    "optAug_va                = False # no Aug in validation!\n",
    "optRepeat_va             = False\n",
    "optLabeled_va            = False\n",
    "optReturnImgNames_va     = True\n",
    "\n",
    "# TEST AUG\n",
    "optAug_tsAug             = True\n",
    "optRepeat_tsAug          = True\n",
    "optLabeled_tsAug         = False\n",
    "optReturnImgNames_tsAug  = False\n",
    "\n",
    "\n",
    "# TEST\n",
    "optAug_ts                = False \n",
    "optRepeat_ts             = False\n",
    "optLabeled_ts            = False\n",
    "optReturnImgNames_ts     = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "shared-ballot",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T23:32:40.191098Z",
     "iopub.status.busy": "2021-05-26T23:32:40.190101Z",
     "iopub.status.idle": "2021-05-27T00:42:51.296974Z",
     "shell.execute_reply": "2021-05-27T00:42:51.297459Z",
     "shell.execute_reply.started": "2021-05-26T12:46:45.133291Z"
    },
    "papermill": {
     "duration": 4211.145208,
     "end_time": "2021-05-27T00:42:51.297698",
     "exception": false,
     "start_time": "2021-05-26T23:32:40.152490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keep patience, takes long ...\n",
      "\n",
      "Processing FOLD 0\n",
      "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b5_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
      "115515392/115515256 [==============================] - 2s 0us/step\n",
      "Model: \"aNetwork\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "imgIn (InputLayer)           [(None, 240, 240, 3)]     0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 240, 240, 3)       0         \n",
      "_________________________________________________________________\n",
      "efficientnet-b5 (Functional) (None, 2048)              28513520  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 28,515,569\n",
      "Trainable params: 28,342,833\n",
      "Non-trainable params: 172,736\n",
      "_________________________________________________________________\n",
      "\n",
      "Training ...\n",
      "Epoch 1/20\n",
      "408/408 [==============================] - 161s 117ms/step - loss: 0.1058 - auc: 0.6800\n",
      "Epoch 2/20\n",
      "408/408 [==============================] - 48s 118ms/step - loss: 0.0867 - auc: 0.7654\n",
      "Epoch 3/20\n",
      "408/408 [==============================] - 48s 117ms/step - loss: 0.0832 - auc: 0.8114\n",
      "Epoch 4/20\n",
      "408/408 [==============================] - 48s 117ms/step - loss: 0.0734 - auc: 0.8082\n",
      "Epoch 5/20\n",
      "408/408 [==============================] - 48s 118ms/step - loss: 0.0747 - auc: 0.8192\n",
      "Epoch 6/20\n",
      "408/408 [==============================] - 48s 117ms/step - loss: 0.0739 - auc: 0.7966\n",
      "Epoch 7/20\n",
      "408/408 [==============================] - 48s 118ms/step - loss: 0.0720 - auc: 0.8300\n",
      "Epoch 8/20\n",
      "408/408 [==============================] - 48s 118ms/step - loss: 0.0713 - auc: 0.8236\n",
      "Epoch 9/20\n",
      "408/408 [==============================] - 48s 118ms/step - loss: 0.0737 - auc: 0.8476\n",
      "Epoch 10/20\n",
      "408/408 [==============================] - 48s 118ms/step - loss: 0.0712 - auc: 0.8471\n",
      "Epoch 11/20\n",
      "408/408 [==============================] - 48s 117ms/step - loss: 0.0755 - auc: 0.8410\n",
      "Epoch 12/20\n",
      "408/408 [==============================] - 48s 117ms/step - loss: 0.0690 - auc: 0.8405\n",
      "Epoch 13/20\n",
      "408/408 [==============================] - 48s 117ms/step - loss: 0.0687 - auc: 0.8452\n",
      "Epoch 14/20\n",
      "408/408 [==============================] - 47s 116ms/step - loss: 0.0751 - auc: 0.8267\n",
      "Epoch 15/20\n",
      "408/408 [==============================] - 48s 117ms/step - loss: 0.0687 - auc: 0.8500\n",
      "Epoch 16/20\n",
      "408/408 [==============================] - 48s 116ms/step - loss: 0.0728 - auc: 0.8723\n",
      "Epoch 17/20\n",
      "408/408 [==============================] - 48s 117ms/step - loss: 0.0729 - auc: 0.8616\n",
      "Epoch 18/20\n",
      "408/408 [==============================] - 48s 118ms/step - loss: 0.0730 - auc: 0.8692\n",
      "Epoch 19/20\n",
      "408/408 [==============================] - 48s 117ms/step - loss: 0.0688 - auc: 0.8796\n",
      "Epoch 20/20\n",
      "408/408 [==============================] - 48s 116ms/step - loss: 0.0694 - auc: 0.8720\n",
      "31/31 [==============================] - 45s 1s/step\n",
      "53/53 [==============================] - 48s 904ms/step\n",
      "\n",
      "Processing FOLD 1\n",
      "Model: \"aNetwork\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "imgIn (InputLayer)           [(None, 240, 240, 3)]     0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 240, 240, 3)       0         \n",
      "_________________________________________________________________\n",
      "efficientnet-b5 (Functional) (None, 2048)              28513520  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 28,515,569\n",
      "Trainable params: 28,342,833\n",
      "Non-trainable params: 172,736\n",
      "_________________________________________________________________\n",
      "\n",
      "Training ...\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 158s 2s/step - loss: 0.2939 - auc: 0.5366\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0798 - auc: 0.7889\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0732 - auc: 0.8538\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0644 - auc: 0.8809\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0658 - auc: 0.8966\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0615 - auc: 0.9030\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0545 - auc: 0.9278\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0562 - auc: 0.9349\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0466 - auc: 0.9580\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0464 - auc: 0.9561\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0446 - auc: 0.9630\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0435 - auc: 0.9655\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0455 - auc: 0.9609\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0385 - auc: 0.9767\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0386 - auc: 0.9691\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0343 - auc: 0.9791\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0301 - auc: 0.9846\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0345 - auc: 0.9755\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0268 - auc: 0.9870\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0292 - auc: 0.9768\n",
      "31/31 [==============================] - 41s 1s/step\n",
      "53/53 [==============================] - 47s 892ms/step\n",
      "\n",
      "Processing FOLD 2\n",
      "Model: \"aNetwork\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "imgIn (InputLayer)           [(None, 240, 240, 3)]     0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 240, 240, 3)       0         \n",
      "_________________________________________________________________\n",
      "efficientnet-b5 (Functional) (None, 2048)              28513520  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 28,515,569\n",
      "Trainable params: 28,342,833\n",
      "Non-trainable params: 172,736\n",
      "_________________________________________________________________\n",
      "\n",
      "Training ...\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 162s 2s/step - loss: 0.2815 - auc: 0.5757\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0779 - auc: 0.8047\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0671 - auc: 0.8658\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0647 - auc: 0.8969\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0652 - auc: 0.8905\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0601 - auc: 0.9164\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0565 - auc: 0.9282\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0537 - auc: 0.9427\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0485 - auc: 0.9455\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0513 - auc: 0.9433\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0454 - auc: 0.9592\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0457 - auc: 0.9529\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0402 - auc: 0.9698\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0369 - auc: 0.9773\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0350 - auc: 0.9787\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0344 - auc: 0.9752\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0292 - auc: 0.9745\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0323 - auc: 0.9800\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0285 - auc: 0.9827\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0243 - auc: 0.9872\n",
      "31/31 [==============================] - 41s 1s/step\n",
      "53/53 [==============================] - 47s 884ms/step\n",
      "\n",
      "Processing FOLD 3\n",
      "Model: \"aNetwork\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "imgIn (InputLayer)           [(None, 240, 240, 3)]     0         \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 240, 240, 3)       0         \n",
      "_________________________________________________________________\n",
      "efficientnet-b5 (Functional) (None, 2048)              28513520  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 28,515,569\n",
      "Trainable params: 28,342,833\n",
      "Non-trainable params: 172,736\n",
      "_________________________________________________________________\n",
      "\n",
      "Training ...\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 164s 2s/step - loss: 0.2846 - auc: 0.5965\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 25s 2s/step - loss: 0.0762 - auc: 0.8134\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0714 - auc: 0.8689\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0710 - auc: 0.8874\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0615 - auc: 0.9124\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0633 - auc: 0.9119\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0571 - auc: 0.9184\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0561 - auc: 0.9342\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0476 - auc: 0.9478\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0472 - auc: 0.9559\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0448 - auc: 0.9482\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0373 - auc: 0.9731\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0405 - auc: 0.9689\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0378 - auc: 0.9721\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0342 - auc: 0.9675\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0336 - auc: 0.9680\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0277 - auc: 0.9841\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0275 - auc: 0.9855\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0282 - auc: 0.9792\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0261 - auc: 0.9888\n",
      "31/31 [==============================] - 41s 1s/step\n",
      "53/53 [==============================] - 47s 880ms/step\n",
      "\n",
      "Processing FOLD 4\n",
      "Model: \"aNetwork\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "imgIn (InputLayer)           [(None, 240, 240, 3)]     0         \n",
      "_________________________________________________________________\n",
      "lambda_4 (Lambda)            (None, 240, 240, 3)       0         \n",
      "_________________________________________________________________\n",
      "efficientnet-b5 (Functional) (None, 2048)              28513520  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 28,515,569\n",
      "Trainable params: 28,342,833\n",
      "Non-trainable params: 172,736\n",
      "_________________________________________________________________\n",
      "\n",
      "Training ...\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 158s 2s/step - loss: 0.2922 - auc: 0.5413\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 25s 2s/step - loss: 0.0793 - auc: 0.7852\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 25s 2s/step - loss: 0.0723 - auc: 0.8525\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 25s 2s/step - loss: 0.0675 - auc: 0.8882\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 25s 2s/step - loss: 0.0626 - auc: 0.8979\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0616 - auc: 0.9079\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0623 - auc: 0.9184\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0562 - auc: 0.9292\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0538 - auc: 0.9354\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0487 - auc: 0.9518\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0457 - auc: 0.9575\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0460 - auc: 0.9576\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0405 - auc: 0.9719\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0386 - auc: 0.9584\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0355 - auc: 0.9774\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0300 - auc: 0.9829\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0354 - auc: 0.9718\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0292 - auc: 0.9838\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0300 - auc: 0.9880\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0266 - auc: 0.9865\n",
      "32/32 [==============================] - 42s 1s/step\n",
      "53/53 [==============================] - 46s 875ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_tr = pd.DataFrame()\n",
    "cnt = 0\n",
    "\n",
    "print('\\nKeep patience, takes long ...')\n",
    "\n",
    "for fold_idx, (tr_idx,va_idx) in enumerate(folds.split(files_train)):\n",
    "    \n",
    "    print('\\nProcessing FOLD {}'.format(fold_idx))\n",
    "    \n",
    "    files_train_tr = files_train[tr_idx]\n",
    "    files_train_va = files_train[va_idx]\n",
    "    \n",
    "    ds_train       = get_dataset(files_train_tr, \n",
    "                                 CFG, \n",
    "                                 augment=optAug_tr, \n",
    "                                 shuffle=optShuffle_tr, \n",
    "                                 repeat=optRepeat_tr\n",
    "                                )\n",
    "    \n",
    "    #ds_train       = ds_train.map(lambda img, label: (img, tuple([label] * CFG['net_count'])))\n",
    "    ds_train       = ds_train.map(lambda img, label: (img, tuple([label])))\n",
    "    \n",
    "    steps_train    = count_data_items(files_train_tr) / (CFG['batch_size'] * REPLICAS)\n",
    "\n",
    "    \n",
    "    # COMPILE MODEL\n",
    "    model          = compile_new_model(CFG)\n",
    "    \n",
    "    # SAVE BEST MODEL EACH FOLD\n",
    "    path_to_best_model = 'fold-%i.h5'%fold_idx\n",
    "    saveBestModel = tf.keras.callbacks.ModelCheckpoint(filepath=path_to_best_model, \n",
    "                                                       monitor='val_loss', \n",
    "                                                       verbose=CFG['verbose'], \n",
    "                                                       save_best_only=True,\n",
    "                                                       save_weights_only=True, \n",
    "                                                       mode='min', \n",
    "                                                       save_freq='epoch'\n",
    "                                                      )\n",
    "    print('\\nTraining ...')\n",
    "    history = model.fit(ds_train, \n",
    "                        epochs           = CFG['epochs'],\n",
    "                        steps_per_epoch  = steps_train,\n",
    "                        verbose          = 1,\n",
    "                        callbacks        = [get_lr_callback(CFG), saveBestModel]\n",
    "                       )\n",
    "    \n",
    "    #print('\\nLoading best model...')\n",
    "    #model.load_weights(path_to_best_model)\n",
    "    \n",
    "    # MAKE TRAIN  PREDICTION\n",
    "    CFG['batch_size'] = 256 # increase batch size\n",
    "\n",
    "    cnt_train   = count_data_items(files_train_va)\n",
    "    steps       = cnt_train / (CFG['batch_size'] * REPLICAS) * CFG['tta_steps']\n",
    "    \n",
    "    ds_trainAug = get_dataset(files_train_va, \n",
    "                              CFG, \n",
    "                              augment=optAug_trAug,\n",
    "                              repeat=optRepeat_trAug,\n",
    "                              labeled=optLabeled_trAug, \n",
    "                              return_image_names=optReturnImgNames_trAug\n",
    "                             )\n",
    "    # Proba\n",
    "    probs = model.predict(ds_trainAug, verbose=1, steps=steps)\n",
    "    probs = probs[:cnt_train * CFG['tta_steps'],:]\n",
    "    probs = np.stack(np.split(probs, CFG['tta_steps'], axis=0), axis=0)\n",
    "    \n",
    "    ds = get_dataset(files_train_va, \n",
    "                     CFG, \n",
    "                     augment=optAug_va, \n",
    "                     repeat=optRepeat_va, \n",
    "                     labeled=optLabeled_va, \n",
    "                     return_image_names=optReturnImgNames_va\n",
    "                    )\n",
    "    \n",
    "    image_names = np.array([img_name.numpy().decode(\"utf-8\") for img, img_name in iter(ds.unbatch())])\n",
    "    \n",
    "    pred = pd.DataFrame(dict(image_name = image_names,\n",
    "                             target     = np.mean(probs[:,:,0], axis=0))\n",
    "                       )\n",
    "    \n",
    "    pred_tr = pd.concat([pred_tr, pred], axis=0)\n",
    "    \n",
    "    # MAKE SUBMISSION DATA\n",
    "    cnt_test   = count_data_items(files_test)\n",
    "    steps      = cnt_test / (CFG['batch_size'] * REPLICAS) * CFG['tta_steps']\n",
    "    \n",
    "    ds_testAug = get_dataset(files_test, \n",
    "                             CFG, \n",
    "                             augment=optAug_tsAug, \n",
    "                             repeat=optRepeat_tsAug, \n",
    "                             labeled=optLabeled_tsAug, \n",
    "                             return_image_names=optReturnImgNames_tsAug\n",
    "                            )\n",
    "\n",
    "    probs = model.predict(ds_testAug, verbose=1, steps=steps)\n",
    "    probs = probs[:cnt_test * CFG['tta_steps'],:]\n",
    "    probs = np.stack(np.split(probs, CFG['tta_steps'], axis=0), axis=0)\n",
    "    \n",
    "    if cnt == 0:\n",
    "        probs_sub = probs/CFG['NSPLITS']\n",
    "        cnt = 1\n",
    "    else:\n",
    "        probs_sub += probs/CFG['NSPLITS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "clean-sixth",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T00:42:57.384615Z",
     "iopub.status.busy": "2021-05-27T00:42:57.342451Z",
     "iopub.status.idle": "2021-05-27T00:42:57.525705Z",
     "shell.execute_reply": "2021-05-27T00:42:57.525121Z",
     "shell.execute_reply.started": "2021-05-26T12:57:20.89661Z"
    },
    "papermill": {
     "duration": 3.187892,
     "end_time": "2021-05-27T00:42:57.525848",
     "exception": false,
     "start_time": "2021-05-27T00:42:54.337956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0015719</td>\n",
       "      <td>1.749516e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0052212</td>\n",
       "      <td>9.477138e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ISIC_0068279</td>\n",
       "      <td>9.612599e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0074268</td>\n",
       "      <td>3.758729e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0074311</td>\n",
       "      <td>4.758650e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0074542</td>\n",
       "      <td>8.761287e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ISIC_0075663</td>\n",
       "      <td>7.627529e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ISIC_0075914</td>\n",
       "      <td>4.484355e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0076262</td>\n",
       "      <td>1.717320e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ISIC_0076545</td>\n",
       "      <td>4.791781e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name        target\n",
       "3  ISIC_0015719  1.749516e-04\n",
       "1  ISIC_0052212  9.477138e-07\n",
       "6  ISIC_0068279  9.612599e-03\n",
       "2  ISIC_0074268  3.758729e-04\n",
       "0  ISIC_0074311  4.758650e-03\n",
       "2  ISIC_0074542  8.761287e-05\n",
       "5  ISIC_0075663  7.627529e-03\n",
       "9  ISIC_0075914  4.484355e-05\n",
       "1  ISIC_0076262  1.717320e-03\n",
       "5  ISIC_0076545  4.791781e-02"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_tr = pred_tr.sort_values('image_name') \n",
    "pred_tr.to_csv('pred_tr.csv', index=False)\n",
    "pred_tr.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "australian-acrylic",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T00:43:03.635031Z",
     "iopub.status.busy": "2021-05-27T00:43:03.634203Z",
     "iopub.status.idle": "2021-05-27T00:43:03.711486Z",
     "shell.execute_reply": "2021-05-27T00:43:03.712277Z",
     "shell.execute_reply.started": "2021-05-26T12:57:21.056049Z"
    },
    "papermill": {
     "duration": 3.097979,
     "end_time": "2021-05-27T00:43:03.712725",
     "exception": false,
     "start_time": "2021-05-27T00:43:00.614746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7233258923127612\n"
     ]
    }
   ],
   "source": [
    "# RESULTS\n",
    "pred_tr = pred_tr.merge(df_train, on = [\"image_name\"], how = \"left\")\n",
    "print(roc_auc_score(pred_tr[\"target_y\"], pred_tr[\"target_x\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-anxiety",
   "metadata": {
    "papermill": {
     "duration": 2.981726,
     "end_time": "2021-05-27T00:43:09.740490",
     "exception": false,
     "start_time": "2021-05-27T00:43:06.758764",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 12. Evaluate on test </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "three-price",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T00:43:15.809098Z",
     "iopub.status.busy": "2021-05-27T00:43:15.808418Z",
     "iopub.status.idle": "2021-05-27T00:43:36.446329Z",
     "shell.execute_reply": "2021-05-27T00:43:36.445778Z",
     "shell.execute_reply.started": "2021-05-26T12:57:21.109631Z"
    },
    "papermill": {
     "duration": 23.698688,
     "end_time": "2021-05-27T00:43:36.446485",
     "exception": false,
     "start_time": "2021-05-27T00:43:12.747797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = get_dataset(files_test, \n",
    "                 CFG, \n",
    "                 augment=optAug_ts, \n",
    "                 repeat=optRepeat_ts, \n",
    "                 labeled=optLabeled_ts, \n",
    "                 return_image_names=optReturnImgNames_ts\n",
    "                )\n",
    "\n",
    "image_names = np.array([img_name.numpy().decode(\"utf-8\") for img, img_name in iter(ds.unbatch())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-development",
   "metadata": {
    "papermill": {
     "duration": 3.050596,
     "end_time": "2021-05-27T00:43:42.589217",
     "exception": false,
     "start_time": "2021-05-27T00:43:39.538621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 13. Submit predictions </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "spectacular-bubble",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T00:43:48.651460Z",
     "iopub.status.busy": "2021-05-27T00:43:48.650764Z",
     "iopub.status.idle": "2021-05-27T00:43:48.716159Z",
     "shell.execute_reply": "2021-05-27T00:43:48.716679Z",
     "shell.execute_reply.started": "2021-05-26T12:57:40.718868Z"
    },
    "papermill": {
     "duration": 3.091359,
     "end_time": "2021-05-27T00:43:48.716855",
     "exception": false,
     "start_time": "2021-05-27T00:43:45.625496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9905</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>0.000253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>0.007753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3120</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>0.002037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4870</th>\n",
       "      <td>ISIC_0073313</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5494</th>\n",
       "      <td>ISIC_0073502</td>\n",
       "      <td>0.001054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4537</th>\n",
       "      <td>ISIC_0074618</td>\n",
       "      <td>0.000401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4819</th>\n",
       "      <td>ISIC_0076801</td>\n",
       "      <td>0.000393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7203</th>\n",
       "      <td>ISIC_0077586</td>\n",
       "      <td>0.001138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10897</th>\n",
       "      <td>ISIC_0082004</td>\n",
       "      <td>0.001803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5093</th>\n",
       "      <td>ISIC_0082785</td>\n",
       "      <td>0.000867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_name    target\n",
       "9905   ISIC_0052060  0.000253\n",
       "1443   ISIC_0052349  0.007753\n",
       "3120   ISIC_0058510  0.002037\n",
       "4870   ISIC_0073313  0.000917\n",
       "5494   ISIC_0073502  0.001054\n",
       "4537   ISIC_0074618  0.000401\n",
       "4819   ISIC_0076801  0.000393\n",
       "7203   ISIC_0077586  0.001138\n",
       "10897  ISIC_0082004  0.001803\n",
       "5093   ISIC_0082785  0.000867"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(dict(image_name = image_names,\n",
    "                               target     = np.mean(probs_sub[:,:,0], axis=0))\n",
    "                               #target     = np.mean(probs, axis = 1))\n",
    "                         )\n",
    "                                        \n",
    "\n",
    "submission = submission.sort_values('image_name') \n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-cover",
   "metadata": {
    "papermill": {
     "duration": 3.086251,
     "end_time": "2021-05-27T00:43:54.848141",
     "exception": false,
     "start_time": "2021-05-27T00:43:51.761890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> References </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-bearing",
   "metadata": {
    "papermill": {
     "duration": 2.974756,
     "end_time": "2021-05-27T00:44:00.886205",
     "exception": false,
     "start_time": "2021-05-27T00:43:57.911449",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- [Notebook] [Incredible TPUs - finetune EffNetB0-B6 at once](https://www.kaggle.com/agentauers/incredible-tpus-finetune-effnetb0-b6-at-once)  \n",
    "- [Notebook] [Triple Stratified KFold with TFRecords](https://www.kaggle.com/cdeotte/triple-stratified-kfold-with-tfrecords)  \n",
    "- [Notebook] [Rotation Augmentation GPU/TPU](https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96)  \n",
    "- [Notebook] [SIIM-ISIC EfficientNet B6 Single Model](https://www.kaggle.com/roydatascience/siim-isic-efficientnet-b6-single-model-lb-0-9475)  \n",
    "- [MSThesis] [Medical images analyses using neural networks](https://ela.kpi.ua/bitstream/123456789/38254/1/Doms_magistr.pdf)  \n",
    "- [TF/Keras] [Keras Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)  \n",
    "- [TF/Keras] [ModelCheckpoint](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint), [see also](https://keras.io/api/callbacks/model_checkpoint/)  \n",
    "- [TF/Keras] [BinaryCrossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy)  \n",
    "- [EfficientNet] [EfficientNet](https://github.com/qubvel/efficientnet)  \n",
    "- [Article] Tan, M. and Le, Q.V. (2019). Efficientnet: rethinking model scaling for convolutional neural networks. arXiv preprint [arXiv:1905.11946](https://arxiv.org/pdf/1905.11946.pdf)\n",
    "- [Article] T. A. Putra, S. I. Rufaida and J. Leu, \"Enhanced Skin Condition Prediction Through Machine Learning Using Dynamic Training and Testing Augmentation,\" in IEEE Access, vol. 8, pp. 40536-40546, 2020, [doi: 10.1109/ACCESS.2020.2976045](https://ieeexplore.ieee.org/document/9007729)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-employment",
   "metadata": {
    "papermill": {
     "duration": 3.069329,
     "end_time": "2021-05-27T00:44:06.928263",
     "exception": false,
     "start_time": "2021-05-27T00:44:03.858934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4328.204215,
   "end_time": "2021-05-27T00:44:13.153868",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-26T23:32:04.949653",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
